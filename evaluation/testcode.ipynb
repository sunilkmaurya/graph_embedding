{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file is to import two embeddings and merge them together to generate\n",
    "# new set of embeddings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data_location = './../generated_embedding/'\n",
    "sec_embed = open(data_location+'citeseer.new_deewalk.embeddings','r')\n",
    "first_embed = open(data_location+'citeseer.edges_struc2vec.embeddings','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes 3327 and length of embedding is 128\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#loading embedding files from deepwalk and struc2vec embeddings\n",
    "#assumption embedding length is 128\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Read the first line and get number of nodes in the embedding\n",
    "temp1 = first_embed.readline()\n",
    "temp2 = sec_embed.readline()\n",
    "temp1 = temp1.split()\n",
    "temp2 = temp2.split()\n",
    "num_node = int(temp1[0])\n",
    "len_embed = int(temp1[1])\n",
    "\n",
    "print(\"number of nodes %s and length of embedding is %s\" % (num_node,len_embed))\n",
    "\n",
    "new_arr = np.ndarray((num_node,2*len_embed),dtype=float)\n",
    "\n",
    "#the code here loads each file in a line and then splits into list values.\n",
    "#First value denotes the node number. That is used to get the index and other values are added to the\n",
    "#array\n",
    "for counter in range(num_node):\n",
    "    temp_embed1 = first_embed.readline().split()\n",
    "    index_one = int(temp_embed1[0])\n",
    "    new_arr[index_one,:len_embed]=[float(i) for i in temp_embed1[1:]]\n",
    "    \n",
    "    temp_embed2 = sec_embed.readline().split()\n",
    "    index_two = int(temp_embed2[0])\n",
    "    new_arr[index_two,len_embed:] = [float(j) for j in temp_embed2[1:]]\n",
    "    \n",
    "'''\n",
    "\n",
    "new_file = open(data_location+\"citeseer_combined.embedding\",'w')\n",
    "for i in range(count):\n",
    "    embed_one = first_embed.readline().split()\n",
    "    embed_two = sec_embed.readline().split()\n",
    "    combine = embed_one+embed_two[1:]\n",
    "    combine = ' '.join(combine)\n",
    "    new_file.write(\"%s\\n\" % combine)\n",
    "\n",
    "'''\n",
    "print(\"finished\")\n",
    "\n",
    "    \n",
    "first_embed.close()\n",
    "sec_embed.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above function seems to work but hard way to check for accuracy.\n",
    "#So I will rewrite the code to add two variables and add them later.\n",
    "\n",
    "\n",
    "def join_embedding(filename1,filename2):\n",
    "    #loading embedding files from deepwalk and struc2vec embeddings\n",
    "    #assumption embedding length is 128\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    data_location = './../generated_embedding/'\n",
    "    first_embed = open(data_location+filename1,'r')\n",
    "    sec_embed = open(data_location+filename2,'r')\n",
    "\n",
    "\n",
    "    #Read the first line and get number of nodes in the embedding\n",
    "    temp1 = first_embed.readline()\n",
    "    temp2 = sec_embed.readline()\n",
    "    temp1 = temp1.split()\n",
    "    temp2 = temp2.split()\n",
    "    num_node = int(temp1[0])\n",
    "    len_embed = int(temp1[1])\n",
    "\n",
    "    print(\"number of nodes %s and length of embedding is %s\" % (num_node,len_embed))\n",
    "\n",
    "    temp_arr1 = np.ndarray((num_node,len_embed),dtype=float)\n",
    "    temp_arr2 = np.ndarray((num_node,len_embed),dtype=float)\n",
    "    new_arr1 = np.ndarray((num_node,2*len_embed),dtype=float)\n",
    "\n",
    "    #the code here loads each file in a line and then splits into list values.\n",
    "    #First value denotes the node number. That is used to get the index and other values are added to the\n",
    "    #array\n",
    "    for counter in range(num_node):\n",
    "        temp_embed1 = first_embed.readline().split()\n",
    "        index_one = int(temp_embed1[0])\n",
    "        temp_arr1[index_one,:]=[float(i) for i in temp_embed1[1:]]\n",
    "    \n",
    "        temp_embed2 = sec_embed.readline().split()\n",
    "        index_two = int(temp_embed2[0])\n",
    "        temp_arr2[index_two,:] = [float(j) for j in temp_embed2[1:]]\n",
    "\n",
    "    #combining two arrays to get one set of embeddings\n",
    "    new_arr1[:,:len_embed] = temp_arr1[:,:]\n",
    "    new_arr1[:,len_embed:] = temp_arr2[:,:]\n",
    "    \n",
    "    first_embed.close()\n",
    "    sec_embed.close()\n",
    "    print(\"finished\")\n",
    "    \n",
    "    return new_arr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: graph_tool module is missing, motif analysis is not available.\n"
     ]
    }
   ],
   "source": [
    "from utils import run_embedding_classify_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_embedding_classify_f1('citeseer',new_arr,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#loading deepwalk embeddings for citeseer\n",
    "\n",
    "f = open(data_location+'citeseer.edgelist_deepwalk.embeddings','r')\n",
    "\n",
    "firstline = f.readline().split()\n",
    "emb_node = int(firstline[0])\n",
    "emb_len = int(firstline[1])\n",
    "\n",
    "deepwalk_embed = np.ndarray((emb_node,emb_len),dtype=np.float32)\n",
    "\n",
    "for i in range(emb_node):\n",
    "    l = f.readline().split()\n",
    "    t_arr = [float(j) for j in l[1:]]\n",
    "    emb_index = int(l[0])\n",
    "    deepwalk_embed[emb_index,:]=t_arr[:]\n",
    "    \n",
    "print(\"finished\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(data_location+'citeseer.new_deewalk.embeddings', 'rb') as efile:\n",
    "        num_node, dim = map(int, efile.readline().split())\n",
    "        emb_matrix = np.ndarray(shape=(num_node, dim), dtype=np.float32)\n",
    "        for data in efile.readlines():\n",
    "            node_id, *vector = data.split()\n",
    "            node_id = int(node_id)\n",
    "            emb_matrix[node_id, :] = np.array([i for i in map(np.float, vector)])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.094527  , -0.013551  , -0.81741297, -0.095326  ,  0.440483  ,\n",
       "        0.34503999, -0.204742  , -1.25870502,  0.131451  , -0.31465501,\n",
       "        0.042019  , -0.056251  , -0.354498  ,  0.450371  , -0.084576  ,\n",
       "       -0.036903  , -0.405341  , -0.48027301, -0.364216  , -0.200618  ,\n",
       "        0.057037  ,  0.32684699,  0.26658899, -0.21323501,  0.441268  ,\n",
       "        0.61049598, -1.75869298,  0.144767  , -0.11791   , -0.018084  ,\n",
       "        0.0329    ,  0.33786201, -1.47459304, -1.34488201,  0.257934  ,\n",
       "       -0.432152  , -0.037146  , -0.53013098,  1.30689204, -1.19934404,\n",
       "       -1.00589502, -0.51819301,  0.355212  , -0.50352502, -0.39936799,\n",
       "       -0.015843  , -0.72176802,  0.65939599, -0.717305  ,  0.51836199,\n",
       "        0.91243201, -0.43010101,  0.410236  ,  0.42614701, -0.135993  ,\n",
       "        0.94635999,  0.238647  ,  0.114305  , -0.18236101,  1.41709602,\n",
       "        0.077559  , -0.28827199,  0.54010898, -0.97638202,  0.211916  ,\n",
       "       -0.55612898, -0.61859697,  0.18791699,  0.25792301, -0.19927999,\n",
       "       -0.68660599,  1.17655301, -0.49244499, -0.087349  ,  0.066049  ,\n",
       "       -0.278056  , -0.61097097,  0.103726  , -0.586294  ,  0.60786802,\n",
       "       -0.70289898,  0.29295799,  0.299876  , -0.81526798,  0.14319   ,\n",
       "       -0.192231  ,  0.124212  , -0.146815  ,  0.17194501, -1.01726997,\n",
       "        0.68748701,  0.94015801,  1.06187296, -0.199664  ,  0.40580499,\n",
       "        0.22903401, -0.078523  ,  0.817128  ,  0.60945499,  1.06925094,\n",
       "        0.40280399, -0.493292  ,  0.046882  , -0.56911302,  0.375339  ,\n",
       "        0.72511601, -0.936948  ,  0.70624399,  1.39368796,  0.89475602,\n",
       "       -0.201125  ,  0.057458  ,  0.40504101, -0.048429  , -0.065051  ,\n",
       "        0.346659  , -0.87393701, -0.80595201,  0.031984  ,  0.451747  ,\n",
       "        0.150903  ,  0.288535  , -0.285705  , -0.29615101,  0.086526  ,\n",
       "       -0.32845399,  0.45982599,  0.029586  ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.094527  , -0.013551  , -0.81741297, -0.095326  ,  0.440483  ,\n",
       "        0.34503999, -0.204742  , -1.25870502,  0.131451  , -0.31465501,\n",
       "        0.042019  , -0.056251  , -0.354498  ,  0.450371  , -0.084576  ,\n",
       "       -0.036903  , -0.405341  , -0.48027301, -0.364216  , -0.200618  ,\n",
       "        0.057037  ,  0.32684699,  0.26658899, -0.21323501,  0.441268  ,\n",
       "        0.61049598, -1.75869298,  0.144767  , -0.11791   , -0.018084  ,\n",
       "        0.0329    ,  0.33786201, -1.47459304, -1.34488201,  0.257934  ,\n",
       "       -0.432152  , -0.037146  , -0.53013098,  1.30689204, -1.19934404,\n",
       "       -1.00589502, -0.51819301,  0.355212  , -0.50352502, -0.39936799,\n",
       "       -0.015843  , -0.72176802,  0.65939599, -0.717305  ,  0.51836199,\n",
       "        0.91243201, -0.43010101,  0.410236  ,  0.42614701, -0.135993  ,\n",
       "        0.94635999,  0.238647  ,  0.114305  , -0.18236101,  1.41709602,\n",
       "        0.077559  , -0.28827199,  0.54010898, -0.97638202,  0.211916  ,\n",
       "       -0.55612898, -0.61859697,  0.18791699,  0.25792301, -0.19927999,\n",
       "       -0.68660599,  1.17655301, -0.49244499, -0.087349  ,  0.066049  ,\n",
       "       -0.278056  , -0.61097097,  0.103726  , -0.586294  ,  0.60786802,\n",
       "       -0.70289898,  0.29295799,  0.299876  , -0.81526798,  0.14319   ,\n",
       "       -0.192231  ,  0.124212  , -0.146815  ,  0.17194501, -1.01726997,\n",
       "        0.68748701,  0.94015801,  1.06187296, -0.199664  ,  0.40580499,\n",
       "        0.22903401, -0.078523  ,  0.817128  ,  0.60945499,  1.06925094,\n",
       "        0.40280399, -0.493292  ,  0.046882  , -0.56911302,  0.375339  ,\n",
       "        0.72511601, -0.936948  ,  0.70624399,  1.39368796,  0.89475602,\n",
       "       -0.201125  ,  0.057458  ,  0.40504101, -0.048429  , -0.065051  ,\n",
       "        0.346659  , -0.87393701, -0.80595201,  0.031984  ,  0.451747  ,\n",
       "        0.150903  ,  0.288535  , -0.285705  , -0.29615101,  0.086526  ,\n",
       "       -0.32845399,  0.45982599,  0.029586  ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepwalk_embed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True], dtype=bool)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(deepwalk_embed[0],emb_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 128, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.618618618619\n",
      "macro: 0.478295367306\n",
      "samples: 0.618618618619\n",
      "weighted: 0.634352029679\n",
      "Accuracy: 0.618618618619\n",
      "Train ratio: 0.5\n",
      "micro: 0.592548076923\n",
      "macro: 0.476271952377\n",
      "samples: 0.592548076923\n",
      "weighted: 0.60087393748\n",
      "Accuracy: 0.592548076923\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.514190317195\n",
      "macro: 0.40189088656\n",
      "samples: 0.514190317195\n",
      "weighted: 0.524775054739\n",
      "Accuracy: 0.514190317195\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.594594594595\n",
      "macro: 0.45796027003\n",
      "samples: 0.594594594595\n",
      "weighted: 0.599856584083\n",
      "Accuracy: 0.594594594595\n",
      "Train ratio: 0.5\n",
      "micro: 0.599759615385\n",
      "macro: 0.476278259825\n",
      "samples: 0.599759615385\n",
      "weighted: 0.610340618199\n",
      "Accuracy: 0.599759615385\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.513188647746\n",
      "macro: 0.427385698593\n",
      "samples: 0.513188647746\n",
      "weighted: 0.519544471677\n",
      "Accuracy: 0.513188647746\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.573573573574\n",
      "macro: 0.452099826591\n",
      "samples: 0.573573573574\n",
      "weighted: 0.579754526481\n",
      "Accuracy: 0.573573573574\n",
      "Train ratio: 0.5\n",
      "micro: 0.584735576923\n",
      "macro: 0.465011385533\n",
      "samples: 0.584735576923\n",
      "weighted: 0.589962151502\n",
      "Accuracy: 0.584735576923\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.467779632721\n",
      "macro: 0.366448949328\n",
      "samples: 0.467779632721\n",
      "weighted: 0.47932258829\n",
      "Accuracy: 0.467779632721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Deepwalk\n",
    "run_embedding_classify_f1('citeseer',emb_matrix,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 256, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.567567567568\n",
      "macro: 0.441948343812\n",
      "samples: 0.567567567568\n",
      "weighted: 0.579208161817\n",
      "Accuracy: 0.567567567568\n",
      "Train ratio: 0.5\n",
      "micro: 0.557091346154\n",
      "macro: 0.448913816824\n",
      "samples: 0.557091346154\n",
      "weighted: 0.563703745978\n",
      "Accuracy: 0.557091346154\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.472787979967\n",
      "macro: 0.371046000394\n",
      "samples: 0.472787979967\n",
      "weighted: 0.481680181878\n",
      "Accuracy: 0.472787979967\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.615615615616\n",
      "macro: 0.493907623061\n",
      "samples: 0.615615615616\n",
      "weighted: 0.62045327382\n",
      "Accuracy: 0.615615615616\n",
      "Train ratio: 0.5\n",
      "micro: 0.5703125\n",
      "macro: 0.455452056464\n",
      "samples: 0.5703125\n",
      "weighted: 0.577341893612\n",
      "Accuracy: 0.5703125\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.484474123539\n",
      "macro: 0.399524791528\n",
      "samples: 0.484474123539\n",
      "weighted: 0.492942048961\n",
      "Accuracy: 0.484474123539\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.573573573574\n",
      "macro: 0.450079025518\n",
      "samples: 0.573573573574\n",
      "weighted: 0.580735499678\n",
      "Accuracy: 0.573573573574\n",
      "Train ratio: 0.5\n",
      "micro: 0.569711538462\n",
      "macro: 0.477289029571\n",
      "samples: 0.569711538462\n",
      "weighted: 0.575186497503\n",
      "Accuracy: 0.569711538462\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.439732888147\n",
      "macro: 0.34253711968\n",
      "samples: 0.439732888147\n",
      "weighted: 0.450591476673\n",
      "Accuracy: 0.439732888147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Deepwalk + Struc2vec combined\n",
    "run_embedding_classify_f1('citeseer',new_arr,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3327, 128)\n",
      "(3327, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3327, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "temp_emb1 = stats.zscore(new_arr[:,:128])\n",
    "print(temp_emb1.shape)\n",
    "temp_emb2 = stats.zscore(new_arr[:,128:])\n",
    "print(temp_emb2.shape)\n",
    "new_temp_emb = np.concatenate((temp_emb1,temp_emb2),axis=1)\n",
    "new_temp_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 256, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.555555555556\n",
      "macro: 0.43922796047\n",
      "samples: 0.555555555556\n",
      "weighted: 0.562974719216\n",
      "Accuracy: 0.555555555556\n",
      "Train ratio: 0.5\n",
      "micro: 0.529447115385\n",
      "macro: 0.427875732745\n",
      "samples: 0.529447115385\n",
      "weighted: 0.532781039604\n",
      "Accuracy: 0.529447115385\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.411686143573\n",
      "macro: 0.326402868962\n",
      "samples: 0.411686143573\n",
      "weighted: 0.415121509161\n",
      "Accuracy: 0.411686143573\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.591591591592\n",
      "macro: 0.475105592338\n",
      "samples: 0.591591591592\n",
      "weighted: 0.595590767326\n",
      "Accuracy: 0.591591591592\n",
      "Train ratio: 0.5\n",
      "micro: 0.530649038462\n",
      "macro: 0.454765965657\n",
      "samples: 0.530649038462\n",
      "weighted: 0.534539605631\n",
      "Accuracy: 0.530649038462\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.420367278798\n",
      "macro: 0.349623276156\n",
      "samples: 0.420367278798\n",
      "weighted: 0.423928096567\n",
      "Accuracy: 0.420367278798\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.561561561562\n",
      "macro: 0.44147964786\n",
      "samples: 0.561561561562\n",
      "weighted: 0.569058247529\n",
      "Accuracy: 0.561561561562\n",
      "Train ratio: 0.5\n",
      "micro: 0.537259615385\n",
      "macro: 0.450023231489\n",
      "samples: 0.537259615385\n",
      "weighted: 0.539758195084\n",
      "Accuracy: 0.537259615385\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.377629382304\n",
      "macro: 0.301491626424\n",
      "samples: 0.377629382304\n",
      "weighted: 0.382616247174\n",
      "Accuracy: 0.377629382304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_embedding_classify_f1('citeseer',new_temp_emb,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
