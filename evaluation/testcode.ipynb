{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This file is to import two embeddings and merge them together to generate\n",
    "# new set of embeddings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data_location = './../generated_embedding/'\n",
    "sec_embed = open(data_location+'citeseer.new_deewalk.embeddings','r')\n",
    "first_embed = open(data_location+'citeseer.edges_struc2vec.embeddings','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes 3327 and length of embedding is 128\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#loading embedding files from deepwalk and struc2vec embeddings\n",
    "#assumption embedding length is 128\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Read the first line and get number of nodes in the embedding\n",
    "temp1 = first_embed.readline()\n",
    "temp2 = sec_embed.readline()\n",
    "temp1 = temp1.split()\n",
    "temp2 = temp2.split()\n",
    "num_node = int(temp1[0])\n",
    "len_embed = int(temp1[1])\n",
    "\n",
    "print(\"number of nodes %s and length of embedding is %s\" % (num_node,len_embed))\n",
    "\n",
    "new_arr = np.ndarray((num_node,2*len_embed),dtype=float)\n",
    "\n",
    "#the code here loads each file in a line and then splits into list values.\n",
    "#First value denotes the node number. That is used to get the index and other values are added to the\n",
    "#array\n",
    "for counter in range(num_node):\n",
    "    temp_embed1 = first_embed.readline().split()\n",
    "    index_one = int(temp_embed1[0])\n",
    "    new_arr[index_one,:len_embed]=[float(i) for i in temp_embed1[1:]]\n",
    "    \n",
    "    temp_embed2 = sec_embed.readline().split()\n",
    "    index_two = int(temp_embed2[0])\n",
    "    new_arr[index_two,len_embed:] = [float(j) for j in temp_embed2[1:]]\n",
    "    \n",
    "'''\n",
    "\n",
    "new_file = open(data_location+\"citeseer_combined.embedding\",'w')\n",
    "for i in range(count):\n",
    "    embed_one = first_embed.readline().split()\n",
    "    embed_two = sec_embed.readline().split()\n",
    "    combine = embed_one+embed_two[1:]\n",
    "    combine = ' '.join(combine)\n",
    "    new_file.write(\"%s\\n\" % combine)\n",
    "\n",
    "'''\n",
    "print(\"finished\")\n",
    "\n",
    "    \n",
    "first_embed.close()\n",
    "sec_embed.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the above function seems to work but hard way to check for accuracy.\n",
    "#So I will rewrite the code to add two variables and add them later.\n",
    "\n",
    "\n",
    "def join_embedding(filename1,filename2):\n",
    "    #loading embedding files from deepwalk and struc2vec embeddings\n",
    "    #assumption embedding length is 128\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    data_location = './../generated_embedding/'\n",
    "    first_embed = open(data_location+filename1,'r')\n",
    "    sec_embed = open(data_location+filename2,'r')\n",
    "\n",
    "\n",
    "    #Read the first line and get number of nodes in the embedding\n",
    "    temp1 = first_embed.readline()\n",
    "    temp2 = sec_embed.readline()\n",
    "    temp1 = temp1.split()\n",
    "    temp2 = temp2.split()\n",
    "    num_node = int(temp1[0])\n",
    "    len_embed = int(temp1[1])\n",
    "\n",
    "    print(\"number of nodes %s and length of embedding is %s\" % (num_node,len_embed))\n",
    "\n",
    "    temp_arr1 = np.ndarray((num_node,len_embed),dtype=float)\n",
    "    temp_arr2 = np.ndarray((num_node,len_embed),dtype=float)\n",
    "    new_arr1 = np.ndarray((num_node,2*len_embed),dtype=float)\n",
    "\n",
    "    #the code here loads each file in a line and then splits into list values.\n",
    "    #First value denotes the node number. That is used to get the index and other values are added to the\n",
    "    #array\n",
    "    for counter in range(num_node):\n",
    "        temp_embed1 = first_embed.readline().split()\n",
    "        index_one = int(temp_embed1[0])\n",
    "        temp_arr1[index_one,:]=[float(i) for i in temp_embed1[1:]]\n",
    "    \n",
    "        temp_embed2 = sec_embed.readline().split()\n",
    "        index_two = int(temp_embed2[0])\n",
    "        temp_arr2[index_two,:] = [float(j) for j in temp_embed2[1:]]\n",
    "\n",
    "    #combining two arrays to get one set of embeddings\n",
    "    new_arr1[:,:len_embed] = temp_arr1[:,:]\n",
    "    new_arr1[:,len_embed:] = temp_arr2[:,:]\n",
    "    \n",
    "    first_embed.close()\n",
    "    sec_embed.close()\n",
    "    print(\"finished\")\n",
    "    \n",
    "    return new_arr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: graph_tool module is missing, motif analysis is not available.\n"
     ]
    }
   ],
   "source": [
    "from utils import run_embedding_classify_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_embedding_classify_f1('citeseer',new_arr,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#loading deepwalk embeddings for citeseer\n",
    "\n",
    "f = open(data_location+'citeseer.edgelist_deepwalk.embeddings','r')\n",
    "\n",
    "firstline = f.readline().split()\n",
    "emb_node = int(firstline[0])\n",
    "emb_len = int(firstline[1])\n",
    "\n",
    "deepwalk_embed = np.ndarray((emb_node,emb_len),dtype=np.float32)\n",
    "\n",
    "for i in range(emb_node):\n",
    "    l = f.readline().split()\n",
    "    t_arr = [float(j) for j in l[1:]]\n",
    "    emb_index = int(l[0])\n",
    "    deepwalk_embed[emb_index,:]=t_arr[:]\n",
    "    \n",
    "print(\"finished\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " with open(data_location+'citeseer.new_deewalk.embeddings', 'rb') as efile:\n",
    "        num_node, dim = map(int, efile.readline().split())\n",
    "        emb_matrix = np.ndarray(shape=(num_node, dim), dtype=np.float32)\n",
    "        for data in efile.readlines():\n",
    "            node_id, *vector = data.split()\n",
    "            node_id = int(node_id)\n",
    "            emb_matrix[node_id, :] = np.array([i for i in map(np.float, vector)])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.094527  , -0.013551  , -0.81741297, -0.095326  ,  0.440483  ,\n",
       "        0.34503999, -0.204742  , -1.25870502,  0.131451  , -0.31465501,\n",
       "        0.042019  , -0.056251  , -0.354498  ,  0.450371  , -0.084576  ,\n",
       "       -0.036903  , -0.405341  , -0.48027301, -0.364216  , -0.200618  ,\n",
       "        0.057037  ,  0.32684699,  0.26658899, -0.21323501,  0.441268  ,\n",
       "        0.61049598, -1.75869298,  0.144767  , -0.11791   , -0.018084  ,\n",
       "        0.0329    ,  0.33786201, -1.47459304, -1.34488201,  0.257934  ,\n",
       "       -0.432152  , -0.037146  , -0.53013098,  1.30689204, -1.19934404,\n",
       "       -1.00589502, -0.51819301,  0.355212  , -0.50352502, -0.39936799,\n",
       "       -0.015843  , -0.72176802,  0.65939599, -0.717305  ,  0.51836199,\n",
       "        0.91243201, -0.43010101,  0.410236  ,  0.42614701, -0.135993  ,\n",
       "        0.94635999,  0.238647  ,  0.114305  , -0.18236101,  1.41709602,\n",
       "        0.077559  , -0.28827199,  0.54010898, -0.97638202,  0.211916  ,\n",
       "       -0.55612898, -0.61859697,  0.18791699,  0.25792301, -0.19927999,\n",
       "       -0.68660599,  1.17655301, -0.49244499, -0.087349  ,  0.066049  ,\n",
       "       -0.278056  , -0.61097097,  0.103726  , -0.586294  ,  0.60786802,\n",
       "       -0.70289898,  0.29295799,  0.299876  , -0.81526798,  0.14319   ,\n",
       "       -0.192231  ,  0.124212  , -0.146815  ,  0.17194501, -1.01726997,\n",
       "        0.68748701,  0.94015801,  1.06187296, -0.199664  ,  0.40580499,\n",
       "        0.22903401, -0.078523  ,  0.817128  ,  0.60945499,  1.06925094,\n",
       "        0.40280399, -0.493292  ,  0.046882  , -0.56911302,  0.375339  ,\n",
       "        0.72511601, -0.936948  ,  0.70624399,  1.39368796,  0.89475602,\n",
       "       -0.201125  ,  0.057458  ,  0.40504101, -0.048429  , -0.065051  ,\n",
       "        0.346659  , -0.87393701, -0.80595201,  0.031984  ,  0.451747  ,\n",
       "        0.150903  ,  0.288535  , -0.285705  , -0.29615101,  0.086526  ,\n",
       "       -0.32845399,  0.45982599,  0.029586  ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.094527  , -0.013551  , -0.81741297, -0.095326  ,  0.440483  ,\n",
       "        0.34503999, -0.204742  , -1.25870502,  0.131451  , -0.31465501,\n",
       "        0.042019  , -0.056251  , -0.354498  ,  0.450371  , -0.084576  ,\n",
       "       -0.036903  , -0.405341  , -0.48027301, -0.364216  , -0.200618  ,\n",
       "        0.057037  ,  0.32684699,  0.26658899, -0.21323501,  0.441268  ,\n",
       "        0.61049598, -1.75869298,  0.144767  , -0.11791   , -0.018084  ,\n",
       "        0.0329    ,  0.33786201, -1.47459304, -1.34488201,  0.257934  ,\n",
       "       -0.432152  , -0.037146  , -0.53013098,  1.30689204, -1.19934404,\n",
       "       -1.00589502, -0.51819301,  0.355212  , -0.50352502, -0.39936799,\n",
       "       -0.015843  , -0.72176802,  0.65939599, -0.717305  ,  0.51836199,\n",
       "        0.91243201, -0.43010101,  0.410236  ,  0.42614701, -0.135993  ,\n",
       "        0.94635999,  0.238647  ,  0.114305  , -0.18236101,  1.41709602,\n",
       "        0.077559  , -0.28827199,  0.54010898, -0.97638202,  0.211916  ,\n",
       "       -0.55612898, -0.61859697,  0.18791699,  0.25792301, -0.19927999,\n",
       "       -0.68660599,  1.17655301, -0.49244499, -0.087349  ,  0.066049  ,\n",
       "       -0.278056  , -0.61097097,  0.103726  , -0.586294  ,  0.60786802,\n",
       "       -0.70289898,  0.29295799,  0.299876  , -0.81526798,  0.14319   ,\n",
       "       -0.192231  ,  0.124212  , -0.146815  ,  0.17194501, -1.01726997,\n",
       "        0.68748701,  0.94015801,  1.06187296, -0.199664  ,  0.40580499,\n",
       "        0.22903401, -0.078523  ,  0.817128  ,  0.60945499,  1.06925094,\n",
       "        0.40280399, -0.493292  ,  0.046882  , -0.56911302,  0.375339  ,\n",
       "        0.72511601, -0.936948  ,  0.70624399,  1.39368796,  0.89475602,\n",
       "       -0.201125  ,  0.057458  ,  0.40504101, -0.048429  , -0.065051  ,\n",
       "        0.346659  , -0.87393701, -0.80595201,  0.031984  ,  0.451747  ,\n",
       "        0.150903  ,  0.288535  , -0.285705  , -0.29615101,  0.086526  ,\n",
       "       -0.32845399,  0.45982599,  0.029586  ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepwalk_embed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True], dtype=bool)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(deepwalk_embed[0],emb_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 128, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.618618618619\n",
      "macro: 0.478295367306\n",
      "samples: 0.618618618619\n",
      "weighted: 0.634352029679\n",
      "Accuracy: 0.618618618619\n",
      "Train ratio: 0.5\n",
      "micro: 0.592548076923\n",
      "macro: 0.476271952377\n",
      "samples: 0.592548076923\n",
      "weighted: 0.60087393748\n",
      "Accuracy: 0.592548076923\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.514190317195\n",
      "macro: 0.40189088656\n",
      "samples: 0.514190317195\n",
      "weighted: 0.524775054739\n",
      "Accuracy: 0.514190317195\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.594594594595\n",
      "macro: 0.45796027003\n",
      "samples: 0.594594594595\n",
      "weighted: 0.599856584083\n",
      "Accuracy: 0.594594594595\n",
      "Train ratio: 0.5\n",
      "micro: 0.599759615385\n",
      "macro: 0.476278259825\n",
      "samples: 0.599759615385\n",
      "weighted: 0.610340618199\n",
      "Accuracy: 0.599759615385\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.513188647746\n",
      "macro: 0.427385698593\n",
      "samples: 0.513188647746\n",
      "weighted: 0.519544471677\n",
      "Accuracy: 0.513188647746\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.573573573574\n",
      "macro: 0.452099826591\n",
      "samples: 0.573573573574\n",
      "weighted: 0.579754526481\n",
      "Accuracy: 0.573573573574\n",
      "Train ratio: 0.5\n",
      "micro: 0.584735576923\n",
      "macro: 0.465011385533\n",
      "samples: 0.584735576923\n",
      "weighted: 0.589962151502\n",
      "Accuracy: 0.584735576923\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.467779632721\n",
      "macro: 0.366448949328\n",
      "samples: 0.467779632721\n",
      "weighted: 0.47932258829\n",
      "Accuracy: 0.467779632721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Deepwalk\n",
    "run_embedding_classify_f1('citeseer',emb_matrix,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 256, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.567567567568\n",
      "macro: 0.441948343812\n",
      "samples: 0.567567567568\n",
      "weighted: 0.579208161817\n",
      "Accuracy: 0.567567567568\n",
      "Train ratio: 0.5\n",
      "micro: 0.557091346154\n",
      "macro: 0.448913816824\n",
      "samples: 0.557091346154\n",
      "weighted: 0.563703745978\n",
      "Accuracy: 0.557091346154\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.472787979967\n",
      "macro: 0.371046000394\n",
      "samples: 0.472787979967\n",
      "weighted: 0.481680181878\n",
      "Accuracy: 0.472787979967\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.615615615616\n",
      "macro: 0.493907623061\n",
      "samples: 0.615615615616\n",
      "weighted: 0.62045327382\n",
      "Accuracy: 0.615615615616\n",
      "Train ratio: 0.5\n",
      "micro: 0.5703125\n",
      "macro: 0.455452056464\n",
      "samples: 0.5703125\n",
      "weighted: 0.577341893612\n",
      "Accuracy: 0.5703125\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.484474123539\n",
      "macro: 0.399524791528\n",
      "samples: 0.484474123539\n",
      "weighted: 0.492942048961\n",
      "Accuracy: 0.484474123539\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.573573573574\n",
      "macro: 0.450079025518\n",
      "samples: 0.573573573574\n",
      "weighted: 0.580735499678\n",
      "Accuracy: 0.573573573574\n",
      "Train ratio: 0.5\n",
      "micro: 0.569711538462\n",
      "macro: 0.477289029571\n",
      "samples: 0.569711538462\n",
      "weighted: 0.575186497503\n",
      "Accuracy: 0.569711538462\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.439732888147\n",
      "macro: 0.34253711968\n",
      "samples: 0.439732888147\n",
      "weighted: 0.450591476673\n",
      "Accuracy: 0.439732888147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Deepwalk + Struc2vec combined\n",
    "run_embedding_classify_f1('citeseer',new_arr,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3327, 128)\n",
      "(3327, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3327, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "temp_emb1 = stats.zscore(new_arr[:,:128])\n",
    "print(temp_emb1.shape)\n",
    "temp_emb2 = stats.zscore(new_arr[:,128:])\n",
    "print(temp_emb2.shape)\n",
    "new_temp_emb = np.concatenate((temp_emb1,temp_emb2),axis=1)\n",
    "new_temp_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sunil/anaconda3/envs/env1/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 256, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.555555555556\n",
      "macro: 0.43922796047\n",
      "samples: 0.555555555556\n",
      "weighted: 0.562974719216\n",
      "Accuracy: 0.555555555556\n",
      "Train ratio: 0.5\n",
      "micro: 0.529447115385\n",
      "macro: 0.427875732745\n",
      "samples: 0.529447115385\n",
      "weighted: 0.532781039604\n",
      "Accuracy: 0.529447115385\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.411686143573\n",
      "macro: 0.326402868962\n",
      "samples: 0.411686143573\n",
      "weighted: 0.415121509161\n",
      "Accuracy: 0.411686143573\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.591591591592\n",
      "macro: 0.475105592338\n",
      "samples: 0.591591591592\n",
      "weighted: 0.595590767326\n",
      "Accuracy: 0.591591591592\n",
      "Train ratio: 0.5\n",
      "micro: 0.530649038462\n",
      "macro: 0.454765965657\n",
      "samples: 0.530649038462\n",
      "weighted: 0.534539605631\n",
      "Accuracy: 0.530649038462\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.420367278798\n",
      "macro: 0.349623276156\n",
      "samples: 0.420367278798\n",
      "weighted: 0.423928096567\n",
      "Accuracy: 0.420367278798\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.561561561562\n",
      "macro: 0.44147964786\n",
      "samples: 0.561561561562\n",
      "weighted: 0.569058247529\n",
      "Accuracy: 0.561561561562\n",
      "Train ratio: 0.5\n",
      "micro: 0.537259615385\n",
      "macro: 0.450023231489\n",
      "samples: 0.537259615385\n",
      "weighted: 0.539758195084\n",
      "Accuracy: 0.537259615385\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.377629382304\n",
      "macro: 0.301491626424\n",
      "samples: 0.377629382304\n",
      "weighted: 0.382616247174\n",
      "Accuracy: 0.377629382304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_embedding_classify_f1('citeseer',new_temp_emb,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3327, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3327, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=128)\n",
    "data_transform = pca.fit_transform(new_arr)\n",
    "data_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 128, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.57957957958\n",
      "macro: 0.441373552466\n",
      "samples: 0.57957957958\n",
      "weighted: 0.594265754558\n",
      "Accuracy: 0.57957957958\n",
      "Train ratio: 0.5\n",
      "micro: 0.566105769231\n",
      "macro: 0.455978764383\n",
      "samples: 0.566105769231\n",
      "weighted: 0.573672038799\n",
      "Accuracy: 0.566105769231\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.475125208681\n",
      "macro: 0.370793668454\n",
      "samples: 0.475125208681\n",
      "weighted: 0.48648202256\n",
      "Accuracy: 0.475125208681\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.597597597598\n",
      "macro: 0.469345700557\n",
      "samples: 0.597597597598\n",
      "weighted: 0.602974643132\n",
      "Accuracy: 0.597597597598\n",
      "Train ratio: 0.5\n",
      "micro: 0.576923076923\n",
      "macro: 0.455247417435\n",
      "samples: 0.576923076923\n",
      "weighted: 0.587618116053\n",
      "Accuracy: 0.576923076923\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.473789649416\n",
      "macro: 0.38876406905\n",
      "samples: 0.473789649416\n",
      "weighted: 0.481967467235\n",
      "Accuracy: 0.473789649416\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.57957957958\n",
      "macro: 0.446398936566\n",
      "samples: 0.57957957958\n",
      "weighted: 0.588576833501\n",
      "Accuracy: 0.57957957958\n",
      "Train ratio: 0.5\n",
      "micro: 0.581730769231\n",
      "macro: 0.458810061818\n",
      "samples: 0.581730769231\n",
      "weighted: 0.590251433929\n",
      "Accuracy: 0.581730769231\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.455091819699\n",
      "macro: 0.355799468629\n",
      "samples: 0.455091819699\n",
      "weighted: 0.46569850828\n",
      "Accuracy: 0.455091819699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_embedding_classify_f1('citeseer',data_transform,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_location = './../data/'\n",
    "g = nx.read_edgelist(graph_location+\"citeseer.edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3327, 3327)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mat = nx.to_numpy_matrix(g)\n",
    "adj_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3327, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=128)\n",
    "data_transform = pca.fit_transform(adj_mat)\n",
    "data_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 128, graph: citeseer\n",
      "\n",
      "Run number 1:\n",
      "Train ratio: 0.9\n",
      "micro: 0.174174174174\n",
      "macro: 0.111687481317\n",
      "samples: 0.174174174174\n",
      "weighted: 0.203786395091\n",
      "Accuracy: 0.174174174174\n",
      "Train ratio: 0.5\n",
      "micro: 0.191105769231\n",
      "macro: 0.113778848918\n",
      "samples: 0.191105769231\n",
      "weighted: 0.232704319557\n",
      "Accuracy: 0.191105769231\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.19632721202\n",
      "macro: 0.115893142539\n",
      "samples: 0.19632721202\n",
      "weighted: 0.237220402746\n",
      "Accuracy: 0.19632721202\n",
      "\n",
      "Run number 2:\n",
      "Train ratio: 0.9\n",
      "micro: 0.192192192192\n",
      "macro: 0.113572636951\n",
      "samples: 0.192192192192\n",
      "weighted: 0.239718459786\n",
      "Accuracy: 0.192192192192\n",
      "Train ratio: 0.5\n",
      "micro: 0.202524038462\n",
      "macro: 0.122506914012\n",
      "samples: 0.202524038462\n",
      "weighted: 0.244802847519\n",
      "Accuracy: 0.202524038462\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.194991652755\n",
      "macro: 0.0880890024583\n",
      "samples: 0.194991652755\n",
      "weighted: 0.270665934654\n",
      "Accuracy: 0.194991652755\n",
      "\n",
      "Run number 3:\n",
      "Train ratio: 0.9\n",
      "micro: 0.162162162162\n",
      "macro: 0.0983468949902\n",
      "samples: 0.162162162162\n",
      "weighted: 0.196162113449\n",
      "Accuracy: 0.162162162162\n",
      "Train ratio: 0.5\n",
      "micro: 0.206129807692\n",
      "macro: 0.13323553483\n",
      "samples: 0.206129807692\n",
      "weighted: 0.237620671181\n",
      "Accuracy: 0.206129807692\n",
      "Train ratio: 0.09999999999999998\n",
      "micro: 0.196994991653\n",
      "macro: 0.0973316019822\n",
      "samples: 0.196994991653\n",
      "weighted: 0.2633584416\n",
      "Accuracy: 0.196994991653\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\envs\\secenv3.5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run_embedding_classify_f1('citeseer',data_transform,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mat[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.37248194e-02,   1.35351087e-02,  -2.45979142e-03,\n",
       "        -4.27657802e-03,  -1.46511699e-02,  -2.81964097e-02,\n",
       "         4.03900167e-04,   8.61116118e-03,  -1.19565004e-03,\n",
       "        -2.39239879e-03,  -5.48842994e-03,  -3.93353297e-03,\n",
       "        -1.19923333e-02,   7.36832386e-03,  -6.04236579e-04,\n",
       "         7.51365259e-04,  -7.72837871e-03,  -7.15928461e-03,\n",
       "        -5.85094392e-03,  -5.14874306e-03,   1.12996806e-03,\n",
       "        -2.96949833e-03,  -4.59418482e-03,  -4.61579532e-03,\n",
       "        -1.62605672e-02,  -4.15038456e-03,   1.42923708e-03,\n",
       "         1.23921627e-03,  -3.41254018e-03,   2.77734385e-03,\n",
       "        -5.97983373e-03,   3.05494117e-04,   5.89126240e-04,\n",
       "        -7.89385887e-04,   1.53020081e-03,  -7.11374982e-03,\n",
       "        -5.34117983e-03,   1.40815817e-03,  -1.14849790e-03,\n",
       "         8.00558625e-04,   2.07831479e-04,  -9.02471543e-03,\n",
       "        -5.32129709e-03,   7.28588819e-04,   3.20453416e-03,\n",
       "        -4.51006355e-03,  -1.13881465e-03,   2.36125846e-04,\n",
       "        -3.87957401e-04,  -2.33711726e-03,   2.11492601e-03,\n",
       "        -4.27088100e-04,  -4.27874566e-03,  -2.36888239e-03,\n",
       "        -6.52565548e-03,  -1.71392699e-03,   8.01858767e-04,\n",
       "         6.03761114e-04,   1.03340789e-03,  -1.21119058e-04,\n",
       "        -7.73573012e-03,  -4.24448764e-03,   1.94074208e-04,\n",
       "         1.83669272e-03,   1.81023440e-03,  -1.44781747e-03,\n",
       "        -9.14088307e-04,  -2.55610831e-03,   7.87225098e-05,\n",
       "         4.79417446e-03,   1.78733153e-03,  -1.84309685e-04,\n",
       "        -4.94092760e-03,  -2.50012615e-03,  -1.53327374e-03,\n",
       "        -1.44737658e-02,  -2.98349916e-03,  -2.71404248e-03,\n",
       "         4.15223041e-03,   3.08578390e-03,  -2.21303000e-04,\n",
       "         9.42032124e-03,   3.39945075e-04,  -3.41690101e-03,\n",
       "         1.01164659e-02,   2.82893693e-03,  -4.87417782e-03,\n",
       "         2.36753466e-03,  -4.35669423e-03,  -1.52580060e-02,\n",
       "        -9.20566826e-03,  -6.10129921e-03,   4.70387090e-03,\n",
       "        -9.77797152e-03,  -8.28029209e-03,   7.15649474e-04,\n",
       "         1.12431353e-03,   2.68745459e-03,   4.08034340e-03,\n",
       "        -8.31724347e-03,  -5.28616412e-03,   8.36897496e-03,\n",
       "         3.82782198e-03,   1.07750855e-02,  -2.94740882e-04,\n",
       "         6.32424817e-04,  -1.13210201e-02,   5.13343775e-03,\n",
       "        -6.12210213e-03,  -1.33305195e-02,   4.76260791e-03,\n",
       "         4.34171188e-03,  -2.02085379e-02,  -1.49373621e-02,\n",
       "         1.20638928e-02,   7.05535217e-03,   5.57350750e-03,\n",
       "         9.52829068e-03,  -4.06096464e-03,  -5.15976537e-03,\n",
       "         6.17025942e-03,   2.85294056e-02,   2.29746706e-03,\n",
       "         3.03547564e-03,  -2.33555862e-02,   2.57835222e-02,\n",
       "        -1.87036372e-02,   1.15195726e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transform[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
