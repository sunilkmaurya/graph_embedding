{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file is to import two embeddings and merge them together to generate\n",
    "# new set of embeddings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data_location = './../generated_embedding/'\n",
    "first_embed = open(data_location+'citeseer.edgelist_deepwalk.embeddings','r')\n",
    "sec_embed = open(data_location+'citeseer.edgelist_struc2vec.embeddings','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes 3327 and length of embedding is 128\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#loading embedding files from deepwalk and struc2vec embeddings\n",
    "#assumption embedding length is 128\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Read the first line and get number of nodes in the embedding\n",
    "temp1 = first_embed.readline()\n",
    "temp2 = sec_embed.readline()\n",
    "temp1 = temp1.split()\n",
    "temp2 = temp2.split()\n",
    "num_node = int(temp1[0])\n",
    "len_embed = int(temp1[1])\n",
    "\n",
    "print(\"number of nodes %s and length of embedding is %s\" % (num_node,len_embed))\n",
    "\n",
    "new_arr = np.ndarray((num_node,2*len_embed),dtype=float)\n",
    "\n",
    "#the code here loads each file in a line and then splits into list values.\n",
    "#First value denotes the node number. That is used to get the index and other values are added to the\n",
    "#array\n",
    "for counter in range(num_node):\n",
    "    temp_embed1 = first_embed.readline().split()\n",
    "    index_one = int(temp_embed1[0])\n",
    "    new_arr[index_one,:len_embed]=[float(i) for i in temp_embed1[1:]]\n",
    "    \n",
    "    temp_embed2 = sec_embed.readline().split()\n",
    "    index_two = int(temp_embed2[0])\n",
    "    new_arr[index_two,len_embed:] = [float(j) for j in temp_embed2[1:]]\n",
    "    \n",
    "'''\n",
    "new_file = open(data_location+\"citeseer_combined.embedding\",'w')\n",
    "for i in range(count):\n",
    "    embed_one = first_embed.readline().split()\n",
    "    embed_two = sec_embed.readline().split()\n",
    "    combine = embed_one+embed_two[1:]\n",
    "    combine = ' '.join(combine)\n",
    "    new_file.write(\"%s\\n\" % combine)\n",
    "'''\n",
    "print(\"finished\")\n",
    "\n",
    "    \n",
    "first_embed.close()\n",
    "sec_embed.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above function seems to work but hard way to check for accuracy.\n",
    "#So I will rewrite the code to add two variables and add them later.\n",
    "\n",
    "\n",
    "def join_embedding(filename1,filename2):\n",
    "    #loading embedding files from deepwalk and struc2vec embeddings\n",
    "    #assumption embedding length is 128\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    data_location = './../generated_embedding/'\n",
    "    first_embed = open(data_location+filename1,'r')\n",
    "    sec_embed = open(data_location+filename2,'r')\n",
    "\n",
    "\n",
    "    #Read the first line and get number of nodes in the embedding\n",
    "    temp1 = first_embed.readline()\n",
    "    temp2 = sec_embed.readline()\n",
    "    temp1 = temp1.split()\n",
    "    temp2 = temp2.split()\n",
    "    num_node = int(temp1[0])\n",
    "    len_embed = int(temp1[1])\n",
    "\n",
    "    print(\"number of nodes %s and length of embedding is %s\" % (num_node,len_embed))\n",
    "\n",
    "    temp_arr1 = np.ndarray((num_node,len_embed),dtype=float)\n",
    "    temp_arr2 = np.ndarray((num_node,len_embed),dtype=float)\n",
    "    new_arr1 = np.ndarray((num_node,2*len_embed),dtype=float)\n",
    "\n",
    "    #the code here loads each file in a line and then splits into list values.\n",
    "    #First value denotes the node number. That is used to get the index and other values are added to the\n",
    "    #array\n",
    "    for counter in range(num_node):\n",
    "        temp_embed1 = first_embed.readline().split()\n",
    "        index_one = int(temp_embed1[0])\n",
    "        temp_arr1[index_one,:]=[float(i) for i in temp_embed1[1:]]\n",
    "    \n",
    "        temp_embed2 = sec_embed.readline().split()\n",
    "        index_two = int(temp_embed2[0])\n",
    "        temp_arr2[index_two,:] = [float(j) for j in temp_embed2[1:]]\n",
    "\n",
    "    #combining two arrays to get one set of embeddings\n",
    "    new_arr1[:,:len_embed] = temp_arr1[:,:]\n",
    "    new_arr1[:,len_embed:] = temp_arr2[:,:]\n",
    "    \n",
    "    first_embed.close()\n",
    "    sec_embed.close()\n",
    "    print(\"finished\")\n",
    "    \n",
    "    return new_arr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: graph_tool module is missing, motif analysis is not available.\n"
     ]
    }
   ],
   "source": [
    "from utils import run_embedding_classify_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_embedding_classify_f1('citeseer',new_arr,splits_ratio=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#loading deepwalk embeddings for citeseer\n",
    "\n",
    "f = open(data_location+'citeseer.edgelist_deepwalk.embeddings','r')\n",
    "\n",
    "firstline = f.readline().split()\n",
    "emb_node = int(firstline[0])\n",
    "emb_len = int(firstline[1])\n",
    "\n",
    "deepwalk_embed = np.ndarray((emb_node,emb_len),dtype=float)\n",
    "\n",
    "for i in range(emb_node):\n",
    "    l = f.readline().split()\n",
    "    t_arr = [float(j) for j in l[1:]]\n",
    "    emb_index = int(l[0])\n",
    "    deepwalk_embed[emb_index,:]=t_arr[:]\n",
    "    \n",
    "print(\"finished\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
